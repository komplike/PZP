{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss_Yoln14U0n",
        "outputId": "4e361c78-b9fd-44d4-e981-ce2a1beeff13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 4.8MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620777 sha256=bd921f27624844bf399292f9aab1c7fe7d8f2cf9ef053cb214e340ac9f9121af\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=2f716683a5eb5bd9cf1060bf2e48e72033dc6a6991f327e3e0931cbcf05b0bf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y556PFwmrOJ"
      },
      "source": [
        "#Hold connection\n",
        "While not using sheet, you should start infinite loop function to hold session. If you want to execute another code, please interupt this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDgSoFLBm_Oe"
      },
      "source": [
        "import time\n",
        "while 1:\n",
        "  time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty0vJSyc28Gi"
      },
      "source": [
        "#Exercise\n",
        "Create two GPU kernels using atomic functions according to logic of given CPU code.\n",
        "\n",
        "First GPU kernel will use shared memory for saving temporal max and min values.\n",
        "\n",
        "Second GPU kernel is version without using shared memory.\n",
        "\n",
        "Compare computational time and results (min, max values) of all algoritms.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQpq2mzJXKaO",
        "outputId": "f5b1c7de-c23b-4a69-d4b0-b1e5fb0d3ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.driver as cuda\n",
        "import numpy\n",
        "import time\n",
        "import math\n",
        "\n",
        "cuda.init()\n",
        "dev = cuda.Device(0)\n",
        "ctx = dev.make_context()\n",
        "\n",
        "numElements = int(1e6)\n",
        "\n",
        "BLOCK_SIZE = 256\n",
        "gridDim = int(numElements/BLOCK_SIZE + 1)\n",
        "print(\"Grid dimension: \"+str(gridDim))\n",
        "\n",
        "kernel_code = ...\n",
        "\n",
        "kernel_code = kernel_code.replace(\"BLOCK_SIZE\", str(BLOCK_SIZE))\n",
        "\n",
        "# Create data\n",
        "input = numpy.random.random(numElements).astype(numpy.float32)\n",
        "\n",
        "# CPU version\n",
        "start = time.time()\n",
        "max = -1000\n",
        "min = 1000\n",
        "\n",
        "for i in range(numElements):\n",
        "    val = int(numpy.arccos(input[i])*180/ 3.14)\n",
        "\n",
        "    if val > max:\n",
        "      max = val\n",
        "    if val < min:\n",
        "      min = val\n",
        "\n",
        "stop = time.time()\n",
        "print(\"\\nCPU Processing time: {0} s\".format(round(stop-start, 3)))\n",
        "print(\"CPU max value: \"+str(max))\n",
        "print(\"CPU min value: \"+str(min))\n",
        "\n",
        "mod = SourceModule(kernel_code)\n",
        "\n",
        "# with shared memory\n",
        "SharedMem = mod.get_function(\"SharedMem\")\n",
        "\n",
        "...\n",
        "\n",
        "\n",
        "# without shared memory\n",
        "WithoutSharedMem = mod.get_function(\"WithoutSharedMem\")\n",
        "\n",
        "...\n",
        "\n",
        "# clean allocated memory\n",
        "...\n",
        "ctx.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grid dimension: 3907\n",
            "\n",
            "CPU Processing time: 4.792 s\n",
            "CPU max value: 90\n",
            "CPU min value: 0\n",
            "\n",
            "GPU Processing time with shared memory: 0.0006 s\n",
            "CPU max value: 90\n",
            "CPU min value: 0\n",
            "\n",
            "GPU Processing time without shared memory: 0.0376 s\n",
            "CPU max value: 90\n",
            "CPU min value: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm3kih2YXKaI"
      },
      "source": [
        "#Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dF2FzQIcfpA",
        "outputId": "06f5c9b8-ddb4-4d09-b8cd-fbf5a757a7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.driver as cuda\n",
        "import numpy\n",
        "import time\n",
        "import math\n",
        "\n",
        "cuda.init()\n",
        "dev = cuda.Device(0)\n",
        "ctx = dev.make_context()\n",
        "\n",
        "numElements = int(1e6)\n",
        "\n",
        "BLOCK_SIZE = 256\n",
        "gridDim = int(numElements/BLOCK_SIZE + 1)\n",
        "print(\"Grid dimension: \"+str(gridDim))\n",
        "\n",
        "kernel_code = \"\"\"\n",
        "__device__ float toDeg = 180/3.14;\n",
        "\n",
        "__global__ void SharedMem(const float *input, int *min, int *max, const int N) \n",
        "{\n",
        "    __shared__ int min_shared[1];  //local block memory cache \n",
        "    __shared__ int max_shared[1];  //local block memory cache  \n",
        "\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(idx < N){\n",
        "\n",
        "        min_shared[0] = 0;\n",
        "        max_shared[0] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        int val = acosf(input[idx])*toDeg;\n",
        "\n",
        "        atomicMin(&(min_shared[0]), val);\n",
        "        atomicMax(&(max_shared[0]), val);\n",
        "        __syncthreads();\n",
        "\n",
        "        // Commit to global memory\n",
        "        if(threadIdx.x == 0){\n",
        "            atomicMin(&min[0], min_shared[0]);\n",
        "            atomicMax(&max[0], max_shared[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void WithoutSharedMem(const float *input, int *min, int *max, const int N)\n",
        "{      \n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(idx < N){\n",
        "      int val = acosf(input[idx]) * toDeg;\n",
        "      atomicMin(min, val);\n",
        "      atomicMax(max, val);\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "kernel_code = kernel_code.replace(\"BLOCK_SIZE\", str(BLOCK_SIZE))\n",
        "\n",
        "# Create data\n",
        "input = numpy.random.random(numElements).astype(numpy.float32)\n",
        "\n",
        "# CPU version\n",
        "start = time.time()\n",
        "max = -1000\n",
        "min = 1000\n",
        "\n",
        "for i in range(numElements):\n",
        "    val = int(numpy.arccos(input[i])*180/ 3.14)\n",
        "\n",
        "    if val > max:\n",
        "      max = val\n",
        "    if val < min:\n",
        "      min = val\n",
        "\n",
        "stop = time.time()\n",
        "print(\"\\nCPU Processing time: {0} s\".format(round(stop-start, 3)))\n",
        "print(\"CPU max value: \"+str(max))\n",
        "print(\"CPU min value: \"+str(min))\n",
        "\n",
        "mod = SourceModule(kernel_code)\n",
        "\n",
        "# with shared memory\n",
        "SharedMem = mod.get_function(\"SharedMem\")\n",
        "\n",
        "min_out = numpy.zeros(1).astype(numpy.int32)\n",
        "max_out = numpy.zeros(1).astype(numpy.int32)\n",
        "\n",
        "input_gpu = cuda.mem_alloc(input.nbytes)\n",
        "min_out_gpu = cuda.mem_alloc(min_out.nbytes)\n",
        "max_out_gpu = cuda.mem_alloc(max_out.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(input_gpu, input)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "SharedMem(input_gpu, min_out_gpu, max_out_gpu, numpy.int32(numElements), block=(BLOCK_SIZE,1,1), grid=(gridDim,1,1), shared=4*2*1)\n",
        "ctx.synchronize()\n",
        "\n",
        "cuda.memcpy_dtoh(min_out, min_out_gpu)\n",
        "cuda.memcpy_dtoh(max_out, max_out_gpu)\n",
        "\n",
        "stop = time.time()\n",
        "print(\"\\nGPU Processing time with shared memory: {0} s\".format(round(stop-start, 4)))\n",
        "print(\"GPU max value: \"+str(max_out[0]))\n",
        "print(\"GPU min value: \"+str(min_out[0]))\n",
        "\n",
        "\n",
        "# without shared memory\n",
        "cuda.memcpy_htod(min_out_gpu, numpy.zeros(1).astype(numpy.float32))\n",
        "cuda.memcpy_htod(max_out_gpu, numpy.zeros(1).astype(numpy.float32))\n",
        "start = time.time()\n",
        "\n",
        "WithoutSharedMem = mod.get_function(\"WithoutSharedMem\")\n",
        "WithoutSharedMem(input_gpu, min_out_gpu, max_out_gpu, numpy.int32(numElements), block=(BLOCK_SIZE,1,1), grid=(gridDim,1,1))\n",
        "ctx.synchronize()\n",
        "\n",
        "cuda.memcpy_dtoh(min_out, min_out_gpu)\n",
        "cuda.memcpy_dtoh(max_out, max_out_gpu)\n",
        "\n",
        "stop = time.time()\n",
        "print(\"\\nGPU Processing time without shared memory: {0} s\".format(round(stop-start, 4)))\n",
        "print(\"GPU max value: \"+str(max_out[0]))\n",
        "print(\"GPU min value: \"+str(min_out[0]))\n",
        "\n",
        "\n",
        "# clean allocated memory\n",
        "input_gpu.free()\n",
        "min_out_gpu.free()\n",
        "max_out_gpu.free()\n",
        "ctx.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grid dimension: 3907\n",
            "\n",
            "CPU Processing time: 4.442 s\n",
            "CPU max value: 90\n",
            "CPU min value: 0\n",
            "\n",
            "GPU Processing time with shared memory: 0.0004 s\n",
            "GPU max value: 90\n",
            "GPU min value: 0\n",
            "\n",
            "GPU Processing time without shared memory: 0.0296 s\n",
            "GPU max value: 90\n",
            "GPU min value: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}